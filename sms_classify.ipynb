{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression for SMS spam classification\n",
    "\n",
    "This project implements the logistic regression to create a spam classifier for SMS messages.\n",
    "\n",
    "Each line of the data file `sms.txt`\n",
    "contains a label---either \"spam\" or \"ham\" (i.e. non-spam)---followed\n",
    "by a text message. Here are a few examples (line breaks added for readability):\n",
    "\n",
    "    ham     Ok lar... Joking wif u oni...\n",
    "    ham     Nah I don't think he goes to usf, he lives around here though\n",
    "    spam    Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.\n",
    "            Text FA to 87121 to receive entry question(std txt rate)\n",
    "            T&C's apply 08452810075over18's\n",
    "    spam    WINNER!! As a valued network customer you have been\n",
    "            selected to receivea £900 prize reward! To claim\n",
    "            call 09061701461. Claim code KL341. Valid 12 hours only.\n",
    "\n",
    "To create features suitable for logistic regression, code is provided to do the following (using tools from the ``sklearn.feature_extraction.text``):\n",
    "\n",
    "* Convert words to lowercase.\n",
    "* Remove punctuation and special characters (but convert the \\$ and\n",
    "  £ symbols to special tokens and keep them, because these are useful for predicting spam).\n",
    "* Create a dictionary containing the 3000 words that appeared\n",
    "  most frequently in the entire set of messages.\n",
    "* Encode each message as a vector $\\mathbf{x}^{(i)} \\in\n",
    "  \\mathbb{R}^{3000}$. The entry $x^{(i)}_j$ is equal to the\n",
    "  number of times the $j$th word in the dictionary appears in that\n",
    "  message.\n",
    "* Discard some ham messages to have an\n",
    "  equal number of spam and ham messages.\n",
    "* Split data into a training set of 1000 messages and a\n",
    "  test set of 400 messages.\n",
    "  \n",
    "The following section completed the following tasks: \n",
    "\n",
    "* Learn $\\boldsymbol{\\theta}$ by gradient descent\n",
    "* Plot the cost history\n",
    "* Make predictions and report the accuracy on the test set\n",
    "* Test out the classifier on a few of your own text messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "\n",
    "from logistic_regression import logistic, cost_function, gradient_descent\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Preprocess the SMS Spam Collection data set\n",
    "#  \n",
    "#   https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "# \n",
    "# From Dan Sheldon\n",
    "\n",
    "numTrain    = 1000\n",
    "numTest     = 494\n",
    "numFeatures = 3000\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# Open the file\n",
    "f = codecs.open('sms.txt', encoding='utf-8')\n",
    "\n",
    "labels = []    # list of labels for each message\n",
    "docs   = []    # list of messages\n",
    "\n",
    "# Go through each line of file and extract the label and the message\n",
    "for line in f:\n",
    "    l, d= line.strip().split('\\t', 1)\n",
    "    labels.append(l)\n",
    "    docs.append(d)\n",
    "\n",
    "# This function will be called on each message to preprocess it\n",
    "def preprocess(doc):\n",
    "    # Replace all currency signs and some url patterns by special\n",
    "    # tokens. These are useful features.\n",
    "    doc = re.sub('[£$]', ' __currency__ ', doc)\n",
    "    doc = re.sub('\\://', ' __url__ ', doc)\n",
    "    doc = doc.lower() # convert to lower\n",
    "    return doc\n",
    "\n",
    "\n",
    "# This is the object that does the conversion from text to feature vectors\n",
    "vectorizer = CountVectorizer(max_features=numFeatures, preprocessor=preprocess)\n",
    "\n",
    "# Do the conversion (\"fit\" the transform from text to feature vector. \n",
    "#   later we will also \"apply\" the tranform on test messages)\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Convert labels to numbers: 1 = spam, 0 = ham\n",
    "y = np.array([l == 'spam' for l in labels]).astype('int')\n",
    "\n",
    "# The vectorizer returns sparse scipy arrays. Convert this back to a dense \n",
    "#   numpy array --- not as efficient but easier to work with\n",
    "X = X.toarray()\n",
    "m,n = X.shape\n",
    "\n",
    "# Add a column of ones\n",
    "X = np.column_stack([np.ones(m), X])\n",
    "\n",
    "# \n",
    "# Now massage and split into test/train\n",
    "# \n",
    "pos = np.nonzero(y == 1)[0]   # indices of positive training examples\n",
    "neg = np.nonzero(y == 0)[0]   # indices of negative training examples\n",
    "\n",
    "npos = len(pos)\n",
    "\n",
    "# Create a subset that has the same number of positive and negative examples\n",
    "subset = np.concatenate([pos, neg[0:len(pos)] ])\n",
    "\n",
    "# Randomly shuffle order of examples\n",
    "np.random.shuffle(subset)\n",
    "      \n",
    "X = X[subset,:]\n",
    "y = y[subset]\n",
    "\n",
    "# Split into test and train\n",
    "train = np.arange(numTrain)\n",
    "test  = numTrain + np.arange(numTest)\n",
    "\n",
    "X_train = X[train,:]\n",
    "y_train = y[train]\n",
    "\n",
    "X_test  = X[test,:]\n",
    "y_test  = y[test]\n",
    "\n",
    "# Extract the list of test documents\n",
    "test_docs = [docs[i] for i in subset[test]]\n",
    "\n",
    "# Extract the list of tokens (words) in the dictionary\n",
    "tokens = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train logistic regresion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X_train     contains information about the words within the training\n",
    "#             messages. the ith row represents the ith training message. \n",
    "#             for a particular text, the entry in the jth column tells\n",
    "#             you how many times the jth dictionary word appears in \n",
    "#             that message\n",
    "#\n",
    "# X_test      similar but for test set\n",
    "#\n",
    "# y_train     ith entry indicates whether message i is spam\n",
    "#\n",
    "# y_test      similar\n",
    "#\n",
    "\n",
    "m, n = X_train.shape\n",
    "\n",
    "theta = np.zeros(n)\n",
    "\n",
    "# YOUR CODE HERE: \n",
    "#  - learn theta by gradient descent\n",
    "alpha = 0.005\n",
    "iters = 300\n",
    "\n",
    "gd = gradient_descent( X_train, y_train, theta, alpha, iters)\n",
    "theta = gd[0]\n",
    "J_history = gd[1]\n",
    "\n",
    "#  - plot the cost history\n",
    "J_x = range(0, iters)\n",
    "plt.plot(J_x, J_history)\n",
    "plt.ylabel(\"Cost function\")\n",
    "plt.show()\n",
    "\n",
    "#  - tune step size and # iterations if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make predictions on test set\n",
    "\n",
    "We can then use the model fit in the previous cell to make predictions on the test set and compute the accuracy (percentage of messages in the test set that are classified correctly). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correctly classified training data:  96.5587 %\n"
     ]
    }
   ],
   "source": [
    "m_test, n_test = X_test.shape\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#  - use theta to make predictions for test set\n",
    "p = logistic(np.dot(X_test, np.transpose(theta)))\n",
    "y_predict = np.round(p,0)\n",
    "\n",
    "#  - print the accuracy on the test set---i.e., the precent of messages classified correctly\n",
    "percentage = (np.sum(y_predict == y_test) / numTest).round(6)*100\n",
    "print(\"Percentage of correctly classified training data: \", percentage, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inspect model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 spam words\n",
      "  +2.8143  __currency__\n",
      "  +2.2106  call\n",
      "  +2.1241  text\n",
      "  +2.0684  txt\n",
      "  +1.8895  reply\n",
      "  +1.7770  service\n",
      "  +1.6672  150p\n",
      "  +1.6297  ringtone\n",
      "  +1.6045  mobile\n",
      "  +1.5618  message\n",
      "\n",
      "Top 10 ham words\n",
      "  -1.4401  my\n",
      "  -1.3702  so\n",
      "  -1.2545  ok\n",
      "  -1.1648  me\n",
      "  -1.0856  later\n",
      "  -1.0713  what\n",
      "  -1.0656  ll\n",
      "  -0.9892  come\n",
      "  -0.9879  he\n",
      "  -0.9204  still\n"
     ]
    }
   ],
   "source": [
    "token_weights = theta[1:]\n",
    "\n",
    "def reverse(a):\n",
    "    return a[::-1]\n",
    "\n",
    "most_negative = np.argsort(token_weights)\n",
    "most_positive = reverse(most_negative)\n",
    "\n",
    "k = 10\n",
    "\n",
    "print('Top %d spam words' % k)\n",
    "for i in most_positive[0:k]:\n",
    "    print('  %+.4f  %s' % (token_weights[i], tokens[i]))\n",
    "\n",
    "print('\\nTop %d ham words' % k)\n",
    "for i in most_negative[0:k]:\n",
    "    print('  %+.4f  %s' % (token_weights[i], tokens[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above examines the model parameters for each word. Positive values are words that tend to be spam and negative values are words that tend to be ham.\n",
    "\n",
    "The top 10 spam and ham words make sense, because they are indeed the words that frequently appear in spam & ham messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Make a prediction on new message\n",
    "\n",
    "We can further play with some sample message and make predictions using the model. As shown below, the predictions do match our expectation for classifying the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 1: ham\n",
      "Message 2: spam\n"
     ]
    }
   ],
   "source": [
    "def extract_features(msg):\n",
    "    x = vectorizer.transform([msg]).toarray()\n",
    "    x = np.insert(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "#  - try a few texts and predict whether they are spam or non-spam\n",
    "msg1 = u\"Test me back when you see this message\"\n",
    "x = extract_features(msg1)\n",
    "p = logistic(np.dot(x, np.transpose(theta)))\n",
    "y_predict = int(np.round(p,0))\n",
    "print('Message 1:', \"spam\" if y_predict== 1 else \"ham\")\n",
    "\n",
    "msg2 = u\"selected to receivea £900 prize reward! To claim call 99999999. Claim code KL341. Or claim at website 900reward.com\"\n",
    "x = extract_features(msg2)\n",
    "p = logistic(np.dot(x, np.transpose(theta)))\n",
    "y_predict = int(np.round(p,0))\n",
    "print('Message 2:', \"spam\" if y_predict== 1 else \"ham\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
